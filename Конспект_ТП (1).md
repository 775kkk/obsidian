# Основные этапы решения задач на ЭВМ

Основные этапы решения задач на ЭВМ.


# Критерии качества программы

Критерии качества программы.


# Программное средство

Программное средство.


# Жизненный цикл программы

Жизненный цикл программы.


# Абстрактные структуры данных

Абстрактные структуры данных.


# Статические и динамические структуры

Статические и динамические структуры.


# Массивы, стеки, очереди, списки, графы, деревья

Массивы, стеки, очереди, списки, графы, деревья.


# Деревья поиска

Деревья поиска.


# Вставка в дерево поиска

Вставка в дерево поиска.


# Удаление из дерева поиска

Удаление из дерева поиска.


# Обход дерева поиска

Обход дерева поиска. Префиксноое дерево.


# Хэш-таблицы

Хэш-таблицы.


# Функция расстановки

Функция расстановки.


# Алгоритм Пирсона

Алгоритм Пирсона.


# Борьба с коллизиями

Борьба с коллизиями – прямое связывание и открытая адресация.


# Суффиксный массив

Суффиксный массив.

Структура данных (англ. data structure) — программная единица, позволяющая хранить и обрабатывать множество однотипных и/или логически связанных данных в вычислительной технике. Структура данных — это способ организации информации для более эффективного использования. 
Для добавления, поиска, изменения и удаления данных структура данных предоставляет некоторый набор функций, составляющих её интерфейс.

Характеристики структур данных следующие:
● Данные в памяти представлены определённым образом, который однозначно позволяет определить структуру.
● Чаще всего внутрь структуры можно добавить элемент или извлечь оттуда. Это свойство не постоянное — бывают структуры, которые нельзя изменять после создания.
● Существуют алгоритмы, которые позволяют взаимодействовать с этой структурой.
При этом данных необязательно должно быть много. Массив из одного элемента — уже структура данных.

Включает в себя: 
Интерфейс (абстракция) – это описание того, какие операции можно выполнять с конкретной структурой данных. Он определяет, какие функции можно вызвать для работы с данными.
Реализация (имплементация) – конкретный способ организации, хранения и управления данными в памяти компьютера с помощью кода, обеспечивающий выполнение операций в соответствии с заданным интерфейсом.





Классификация по связности:
Связность определяет, существует ли явная связь между элементами структуры, и как эта связь организована.
Несвязные (линейный, неявные) – элементы располагаются в памяти подряд без указателей на другие элементы, связь между ними – по индексу или позиции (динамический/массив, стек, очередь)
Связные структуры(явные) – каждый элемент содержит указатель на следующий. Связь – через ссылки. Элементы располагаются в разных местах памяти (одно/двух-связный список, кольцевой список)
Несвязанные – элементы никак не связаны и не упорядочены (множество)

Классификация по статике/динамике:
Статические – размер фиксирован, не меняется после создания (массив)
Динамические – может изменяться размер во время выполнения программы(связные списки(одно/двух), деревья, графы, очередь, стек.

Массив – структура данных, представляющая собой последовательный набор элементов одного типа, расположенных в непрерывной области памяти (подряд). Доступ к элементу осуществляется быстро и одинаково ко всем.
Стек – структура данных, работающая по принципу «последний добавленный элемент извлекается первым»
Очередь - структура данных, работающая по принципу «первый добавленный элемент, извлекается первым»
Списки - структура данных, представляющая собой упорядоченный набор элементов, каждый из которых содержит ссылку(указатель) на следующий элемент 
- Односвязный список – каждый элемент содержит данные и ссылку га следующий узел.
- Двусвязный список – каждый узел содержит данные, ссылку на следующий и предыдущий узлы.
- Кольцевой список – последний элемент ссылается на первый, образуя кольцо.


# Алгоритм Бауэра вычисления алгебраического выражения

Алгоритм Бауэра вычисления алгебраического выражения.


# Обратная польская запись

Обратная польская запись (ОПЗ).


# Алгоритм перевода формулы в ОПЗ

Алгоритм перевода формулы в ОПЗ.


# Генерация кода для стековой машины

Генерация кода для стековой машины.

Вычисление алгебраических выражений – одна из фундаментальных задач в математике и программировании. Основная трудность при создании компиляторов заключалась в неоднозначности порядка выполнения операций и необходимости обработки скобок. Язык Fortran – первый шаг в этом направлении.

Fortran - это старый, но до сих пор используемый язык программирования, изначально разработанный для математических и научных вычислений. Его полное название - FORmula TRANslation. Он отличался от других языков своей способностью напрямую переводить математические формулы в машинный код, что делало его удобным для программистов, работающих с научными и инженерными задачами. 

Алгоритм Г. Рутисхаузера работает с выражениями, в которых каждая операция заключена в скобки, поэтому порядок выполнения задаётся полностью скобками. Суть алгоритма: повторно искать самую вложенную подформулу, вычислять её на число. Повторять, пока не останется одно значение.  Алгоритм неудобен из-за сложности в программной реализации и громоздкости

После Г.Рутисхаузера было придумано несколько алгоритмов.
польский математик  Я. Лукашевич;
австралийский математик и философ Ч.Хэмблин
немецкие математики К. Замельзон и  Ф. Бауэр;
     - 	  нидерландский математик Э. Дейкстра

Алгоритм Ф. Бауэра и К. Замельзона.
В алгоритме используются две структуры. Два стека  - S1, хранящий операнды(числа) и S2, хранящий операции ( + - * / ( ) ).
Далее присваиваем операциям приоритеты 
( 	 –	 приоритет 0;
 + - 	–	 приоритет 1;
 * /  	–	 приоритет 2;
 ^	– 	 приоритет 3.
Выражения разбиваем на лексемы – минимальный логически неделимый элемент выражения. Они нужны для лексического анализа – первого шага при разборе любой формулы или программы, поскольку компьютер при разборе выражения должен понимать, где заканчивается одно число и начинается операция. 

Для каждой лексемы: 
Если лексема – число, то помещаем в стек 1. 
Если лексема – ( , то помещаем в стек 2. 
Если лексема операция, то помещаем в стек 2, если он пуст. Иначе сравниваем приоритет новой операции с вершиной стека 2. 
Если приоритет новой операции больше, то помещаем в стек 2
Если меньше или равен, то извлекаем две верхние лексемы из стека 1.
Извлекаем верхнюю операцию из стека 2.
Вычисляем результат. Помещаем обратно в стек 1. Продолжаем пока не станет возможным положить новую операцию в стек 2.

Если лексема - ) , то последовательно выполняем операции из стека 2, пока не найдём (.

Когда лексемы закончились, опустошаем стек 2: берём две вершины стека 1, одну операцию из стека 2, вычисляем, кладём обратно в стек 1. 
В конце стека 1 должно остаться одно значение – результат выражения.

- Инфиксная форма
Форма записи алгебраических выражений, в которых знак операции размещается между операндами, называется инфиксной.
2 + 3
Недостаток – требуется скобки и приоритеты для однозначной интерпретации. 

 - Постфиксная форма (ОПЗ)
Операция стоит после операндов
2 3 +
Удобно вычислять с помощью стека. 

- Префиксная форма
Операция стоит перед операндами. 
+ 2 3
Удобна для рекурсивной обработки.

-


# Оценка вычислительной сложности алгоритмов

Оценка вычислительной сложности алгоритмов.


# Символ “О большое”

Символ “О большое”.
Сложность алгоритмов обычно оценивают по времени выполнения или по используемой памяти. В обоих случаях сложность зависит от размеров входных данных: массив из 100 элементов будет обработан быстрее, чем аналогичный из 1000. При этом точное время мало кого интересует: оно зависит от процессора, типа данных, языка программирования и множества других параметров. Важна лишь асимптотическая сложность, т. е. сложность при стремлении размера входных данных к бесконечности.
Использование заглавной буквы О (или так называемая О-нотация) пришло из математики, где её применяют для сравнения асимптотического поведения функций. Формально O(f(n)) означает, что время работы алгоритма (или объём занимаемой памяти) растёт в зависимости от объёма входных данных не быстрее, чем некоторая константа, умноженная на f(n).
O(1) — Константная (постоянная) сложность. 
Алгоритмы с константной временной сложностью выполняются за одно и то же время вне зависимости от количества элементов. Например, в упорядоченном массиве минимальный элемент всегда находится в самом начале, поэтому поиск минимума становится тривиальным.
O(n) — линейная сложность
Такой сложностью обладает, например, алгоритм поиска наибольшего элемента в не отсортированном массиве. Нам придётся пройтись по всем n элементам массива, чтобы понять, какой из них максимальный.
O(log2 n) — логарифмическая сложность
Простейший пример — бинарный поиск. Если массив отсортирован, мы можем проверить, есть ли в нём какое-то конкретное значение, методом деления пополам. Проверим средний элемент, если он больше искомого, то отбросим вторую половину массива — там его точно нет. Если же меньше, то наоборот — отбросим начальную половину. И так будем продолжать делить пополам, в итоге проверим log2 n элементов.
O(n log n) — линейно-логарифмическая
n – означает, что мы обрабатываем каждый элемент. 
log – означает, что для каждого элемента выполняется какое-то кол-во операций, зависящее от логарифма входного размера (деление пополам).
Сортировка слиянием, быстрая сортировка, пирамидальная сортировка.
O(n^2) — квадратичная сложность
Такую сложность имеет, например, алгоритм сортировки вставками, выбором, пузырьковая. В канонической реализации он представляет из себя два вложенных цикла: один, чтобы проходить по всему массиву, а второй, чтобы находить место очередному элементу в уже отсортированной части.
O(n^3) — кубическая сложность. 
Время выполнения алгоритма зависит от размера входных данных в кубе. Например, алгоритмы, которые имеют три вложенных цикла, такие как некоторые методы многомерной обработки данных.
O(2^n) — экспоненциальная.
Каждое увеличение входных данных на 1 приводит к удвоению кол-ва операций
Рекурсивный перебор всех подмножеств, решение задачи о Рюкзаке, рекурсивное решение задачи о Фибоначчи
O(n!) — факториальная сложность. 
Это самая высокая степень роста времени выполнения алгоритма. Время выполнения алгоритма растет факториально от размера входных данных. Этот тип сложности встречается, например, при переборе всех возможных комбинаций элементов, что делает его чрезвычайно неэффективным для больших значений n.


# Двоичный поиск

Двоичный поиск.


# Количество проверок при двоичном поиске

Количество проверок при двоичном поиске.


# Сортировка данных и её отличие от фильтрации

Сортировка данных и её отличие от фильтрации.


# Устойчивость и естественность сортировки

Устойчивость и естественность сортировки.


# Простейшие алгоритмы сортировки

Простейшие алгоритмы сортировки (пузырьковая, вставками, выбором).

Сортировка — это перестановка заданного массива или списка элементов в соответствии с оператором сравнения элементов. Он используется для определения их нового порядка в соответствующей структуре данных. Сортировка переупорядочивает все элементы либо по возрастанию, либо по убыванию.

Пузырьковая сортировка (Bubble Sort). Простейший алгоритм, который сравнивает пары соседних элементов и меняет их местами. Несмотря на свою простоту, это один из наименее эффективных алгоритмов со сложностью O(n2).  Принцип действий прост: обходим массив от начала до конца, попутно меняя местами неотсортированные соседние элементы. В результате первого прохода на последнее место «всплывёт» максимальный элемент. Теперь снова обходим неотсортированную часть массива (от первого элемента до предпоследнего) и меняем по пути неотсортированных соседей. Второй по величине элемент окажется на предпоследнем месте. Продолжая в том же духе, будем обходить всё уменьшающуюся неотсортированную часть массива, запихивая найденные максимумы в конец. Алгоритм завершает работу, когда на очередном цикле просмотра не выполняется ни одной перестановки.
- Производительность ~ O(n2)
- Устойчивая 
- Поведение не вполне естественное

Сортировка Выбором. Проходим по массиву в поисках максимального элемента. Найденный максимум меняем местами с последним элементом. Неотсортированная часть массива уменьшилась на один элемент (не включает последний элемент, куда мы переставили найденный максимум). К этой неотсортированной части применяем те же действия — находим максимум и ставим его на последнее место в неотсортированной части массива. И так продолжаем до тех пор, пока неотсортированная часть массива не уменьшится до одного элемента. Сортировка простым выбором представляет из себя грубый двойной перебор.

Сортировка Вставками


# Источники ошибок в программных средствах

Источники ошибок в программных средствах.


# Тестирование программных средств

Тестирование программных средств.


# Тестирование по принципам "белого" и "черного ящика"

Тестирование по принципам "белого" и "черного ящика".

1. Ошибки проектирования
Возникают на этапе планирования. Программу задумывают неправильно: либо требования сформулированы неточно, либо архитектура системы не учитывает будущие потребности. В итоге ПО не делает то, что от него ожидают.

2. Ошибки реализации
Это ошибки, которые допускает программист при написании кода. Например: неправильные формулы, перепутанные переменные, неверная логика условий и циклов. Программа работает, но результат — неправильный.

3. Ошибки тестирования
Происходят из-за того, что программу проверяют недостаточно или неправильно. Например, не протестировали редкие случаи, или сами тесты содержат ошибки. В результате баги остаются незамеченными.

4. Ошибки сопровождения
Появляются при доработке и поддержке программы. Если вносить изменения без полного понимания кода, можно нарушить работу уже существующих функций или создать новые проблемы.

5. Ошибки взаимодействия
Проявляются, когда разные части системы работают вместе. Например, один модуль ожидает данные в одном формате, а другой — передаёт в другом. Или программа неправильно обрабатывает данные от пользователя или других систем.

6. Ошибки, вызванные внешними факторами
Иногда проблемы возникают не из-за самого ПО, а из-за внешних условий: неполадки в компьютере, перебои в интернете, ошибки в операционной системе или сторонних библиотеках

Тестирование программного обеспечения (Software Testing) — проверка соответствия реальных и ожидаемых результатов поведения программы, проводимая на конечном наборе тестов, выбранном определённым образом.
Цель тестирования — проверка соответствия ПО предъявляемым требованиям, обеспечение уверенности в качестве ПО, поиск очевидных ошибок в программном обеспечении, которые должны быть выявлены до того, как их обнаружат пользователи программы.

Представим, что продукт (его код, инфраструктура, взаимосвязи) находится в коробке.
При тестировании «белого ящика», или white box testing, коробка прозрачна. Тестировщик будет видеть, как реализован продукт, какое дополнительное ПО подключено для его функционирования, какие взаимосвязи используются.
Тестирование «черного ящика», или black box testing, — это непрозрачная коробка. Тестировщик не имеет ни малейшего понятия, с какими взаимосвязями и сервисами предстоит работать. Проверяется только логика функционирования продукта.
Обычно методы «белого» и «черного ящика» работают в связке. Например, если в компании протестировали продукт по методу «черного ящика» и ничего не нашли, то потом продукт могут передать на проверку по методу «белого ящика» и выявить уязвимости, которые не заметили в первый раз.
Тестирование «белого ящика» используется и на ранних стадиях разработки, когда функции еще не дописаны и взаимосвязи не настроены. Метод позволяет выявить противоречия и ошибки в коде на первых этапах создания продукта, чтобы они не затормозили разработку в дальнейшем. А тестирование «черного ящика» применяется, когда продукт уже готов, чтобы финально проверить его логику и функции

«Черный ящик». Специалисты проверяют функциональность продукта, взяв на себя роль реальных пользователей. Например, в интернет-магазине они пытаются сделать заказ или добавить товар в избранное. Проверяют на актуальность версии движков и плагинов, если они есть в веб-приложениях. При этом тестировщики не залезают в код и не смотрят инфраструктуру продукта. 
Вот что может проверять метод «черный ящик»:
Функциональность. Насколько корректно выполняются функции и задуманные сценарии. Например, нет ли багов в приложении для вызова такси, когда пользователь отмечает точку на карте или пишет комментарий.
Удобство использования. Насколько комфортно пользоваться продуктом. Например, быстро ли пользователь интернет-магазина может найти нужный товар, нет ли трудностей с оплатой и выбором способа доставки.
Совместимость. Правильно ли продукт работает на различных операционных системах и устройствах, интегрируется ли с другими ресурсами. Например, синхронизируется ли мессенджер с контактами в смартфоне. 
Стабильность. Как продукт реагирует на большое количество пользователей или DDoS-атаки. Например, сайт интернет-магазина не должен «повиснуть», если после объявления распродажи на него зайдет в несколько раз больше пользователей, чем обычно.  

«Белый ящик». Тестировщики получают доступ к коду, чтобы выявить слабые места, которые пока незаметны при повседневном использовании, но могут причинить неудобства в дальнейшем. Например, выявят уязвимости, через которые в продукт могут проникнуть злоумышленники, или неоптимизированные куски кода, которые потом затормозят работу продукта.
При тестировании методом «белый ящик» сначала проверяют сам сайт или приложение, а затем — инфраструктуру. Если специалисты смогут найти уязвимость в сайте, они проникнут во внутреннюю сеть сами. Если этого не получилось сделать, доступ предоставляет заказчик. 



Вот что может проверять метод «белый ящик»:
Уязвимости. Есть ли в коде и системе безопасности сайта бреши, через которые могут проникнуть злоумышленники. Например, хакеры могут ввести в форму обратной связи вредоносный код, и если система его не заблокирует, то сайт может упасть.
Структура и чистота кода. Чем запутаннее код, тем сложнее будет дорабатывать продукт. В нем не должно быть лишних или сломанных элементов, которые в дальнейшем могут вызвать ошибки.
Ожидаемые результаты. Как и в методе «черного ящика», тестировщики проверяют, правильно ли функционирует продукт. 
Но работают не с интерфейсом, а непосредственно с кодом. Они вводят определенные команды и смотрят, какой код после этого появляется. 
Выполнение циклов. Корректно ли выполняется цикл действий, запущенный определенной командой. Например, если покупатель в интернет-магазине нажал «Оплатить», то сайт должен обработать его данные, получить ответ от банка, вывести результат на экран и отправить пользователю чек на почту.


# Особенности операций с плавающей точкой

Особенности операций с плавающей точкой.


# Представление чисел с плавающей точкой в компьютере

Представление чисел с плавающей точкой в компьютере.


# Причины погрешности операций с плавающей точкой

Причины погрешности операций с плавающей точкой.

Числа с плавающей точкой – это приближённое представление вещественных чисел в компьютере. Число с плавающей запятой состоит из набора отдельных разрядов, условно разделенных на знак,  экспоненту порядок и мантиссу. Порядок и мантисса — целые числа, которые вместе со знаком дают представление числа с плавающей запятой в следующем виде:



Мантисса – это целое число фиксированной длины, которое представляет старшие разряды действительного числа. Допустим наша мантисса состоит из трех бит (|M|=3). Возьмем, например, число «5», которое в двоичной системе будет равно 1012. Старший бит соответствует 22=4, средний (который у нас равен нулю) 21=2, а младший 20=1. 
Порядок – это степень базы (двойки) старшего разряда. В нашем случае E=2. Такие числа удобно записывать в так называемом «научном» стандартном виде, например «1.01e+2». Сразу видно, что мантисса состоит из трех знаков, а порядок равен двум.


Число с плавающей запятой состоит из набора отдельных двоичных разрядов, условно разделенных на так называемые знак (англ. sign), порядок (англ. exponent) и мантиссу (англ. mantis). 
Под числа с плавающей точкой даже создан единый стандарт IEEE 754 — чтобы все компьютеры, языки программирования, программы и операционные системы работали с ними одинаково и результат получался предсказуемым. 

В наиболее распространённом формате (стандарт IEEE 754) число с плавающей запятой представляется в виде набора битов, часть из которых кодирует собой мантиссу числа, другая часть — показатель степени, и ещё один бит используется для указания знака числа (00 — если число положительное, 11 — если число отрицательное). При этом порядок записывается как целое число в коде со сдвигом, а мантисса — в нормализованном виде, своей дробной частью в двоичной системе счисления.
Форма представления числа с плавающей точкой, в которой первый разряд мантиссы не равен нулю, называется нормализованной.





Представление числа.
1) Преобразование в двоичной с.с. целой и дробной части
13.25 -> 1101.01
2) Сдвиг запятой, чтобы остался 1 знак перед запятой. На сколько сдвиг = порядок числа.
1.10101
3) Порядок(экспонента): Стандарт требует хранения порядка со смещением (bias = 127 для float). Порядок = сдвиг (3) + 127. Перевод в двоичную с.с.
130 = 10000010
4) Мантисса: оставшаяся часть после запятой в формате 23 бита. 

Самая главный показатель, от которого зависит точность вычислений с плавающей точкой – длина мантиссы.

Особенности операций

1 Ограниченная точность:
Для числа типа float(32бита) и double(64бита) имеют разное кол-во битов под мантиссу и порядок. Float ~ 7 десятичных цифр, double ~15 д.ц. Это значит, что не все десятичные дроби можно представить точно.

2 Неассоциативность арифметики:
Для чисел с плавающей точкой ассоциативный закон может нарушаться, потому что каждое промежуточное вычисление округляется до длины мантиссы.
Погрешности при выравнивании порядков:
Чтобы сложить два числа, компьютер вынужден выравнивать порядки. Если разность порядков слишком велика – меньшее полностью игнорируется.

3 Вычитание близких по значению чисел.
Когда два числа близки другу к другу по значению, их вычитание приводит к резкому уменьшению кол-ва значащих цифр

4 Ошибки округления
Каждая операция (сложение, умножение и т.д.) производится с округлением результата до длины мантиссы. Это создаёт погрешность, при множестве операций возможно потеря значащих цифр.

5 Ошибка при сравнении
Числа с плавающей точкой нельзя сравнивать напрямую с помощью оператора ==
Способ 1: сравнение с абсолютной погрешностью через eps.


# Алгоритм RLE сжатия данных

Алгоритм RLE сжатия данных.


# Алгоритм Хаффмана

Алгоритм Хаффмана.


# Построение дерева Хаффмана и битового кода

Построение дерева Хаффмана и битового кода.


# Алгоритм LZW сжатия данных

Алгоритм LZW сжатия данных.


# Арифметическое сжатие данных

Арифметическое сжатие данных. 

Алгоритм RLE(Run-Length-Encoding – кодирование длины пробега) является самым простейшим из всех: суть его заключается в кодировании повторов. Другими словами, мы берём последовательности одинаковых элементов, и «схлопываем» их в пары «количество/значение». Например, строка вида «AAAAAAAABCCCC» может быть преобразована в запись вроде «8×A, B, 4×C».
hex-дамп:
0000: 00 00 00 00 00 00 04 02 00 04 04 04 04 04 04 04
0010: 50 50 50 50 00 02 02 02 02 FF FF FF FF FF 00 00

6×0, 4, 2, 0, 7×4, 4×80, 0, 4×2, 5×255, 2×0.

Алгоритм кодирования Хаффмана обладает свойством префиксности, а, кроме того, доказанной минимальной избыточностью, именно этим обусловлено его крайне широкое распространение. 
Для получения кодов Хаффмана используют следующий алгоритм:
1. Все символы алфавита представляются в виде свободных узлов, при этом вес узла пропорционален частоте символа в сообщении;
2. Из множества свободных узлов выбираются два узла с минимальным весом и создаётся новый (родительский) узел с весом, равным сумме весов выбранных узлов;
3. Выбранные узлы удаляются из списка свободных, а созданный на их основе родительский узел добавляется в этот список;
4. Шаги 2-3 повторяются до тех пор, пока в списке свободных больше одного узла;
5. На основе построенного дерева каждому символу алфавита присваивается префиксный код;
6. Сообщение кодируется полученными кодами.

Этапы построения дерева Хаффмана:
1) Посчитаем частоту символов во входных данных
2) Создадим узлы для каждого символа и частоту
3) Расставим символу и их частоту в порядке убывания
4) На каждом шаге берем два узла с минимальными весами, объединяем их в новый узел и приписываем ему суммарный вес
5) Теперь для каждого символа-участника можно получить его битовый код.
Для этого нужно найти путь от корня дерева к нужному символу, приписывая к коду 0 при повороте влево, и 1 при повороте вправо



Алгоритм обладает свойством префиксности: ни один код не начинается с другого. Это гарантирует, что при чтении потока битов можно однозначно понять, где один символ заканчивается, а следующий – начинается.
Декодирование Хаффмана. Начинаем читать биты слева направо, постепенно сопоставляем прочитанную последовательность с кодами (буквами). Как только найдено совпадение – добавляем символ в расшифровку.


# Коды, исправляющие ошибки

Коды, исправляющие ошибки.


# Расстояние Хэмминга

Расстояние Хэмминга.


# Фундаментальные соотношения для расстояния Хэмминга

Фундаментальные соотношения для расстояния Хэмминга, обеспечивающие фиксацию и исправление ошибок.


# Рекурсия

Рекурсия.


# Требования к рекурсивным программам

Требования к рекурсивным программам.


# Терминальная ветвь рекурсии

Терминальная ветвь рекурсии.


# Примеры рекурсивных программ

Примеры рекурсивных программ.


# Виды рекурсии

Виды рекурсии.


# Графы

графы, деревья.


# Машинное представление графов

Машинное представление графов (матрица смежности, матрица инцидентности, списки вершин).
Граф – абстрактная структура данных, состоящая из вершин и рёбер
Обозначим множество вершин буквой V от английского vertex−вершина и множество рёбер обозначим E от английского edge−ребро. Граф в формулах именуют буквой G. Все вершины обязательно должны быть идентифицированы.
G = (V, E) – формально математическое определение графов. 
V = {1, 2, 3, 4,}существует 4 вершины в графе
E = { {1, 2}, {2,3}, {3,4} } существует ребро между вершинами 1 и 2
Количество вершин называется порядком графа.
Количество ребер называется размером графа.


# Общая схема обхода вершин графа

Общая схема обхода вершин графа.


# Поиск в глубину в графе

Поиск в глубину в графе.


# Поиск в ширину в графе

Поиск в ширину в графе.
Обходом графа называется перебор его вершин, при котором каждая вершина просматривается один раз. При этом от вершины к вершине можно переходить только по рёбрам. 

Двумя основными алгоритмами обхода графа являются поиск в глубину (Depth-First Search, DFS) и поиск в ширину (Breadth-First Search, BFS).
Поиск в глубину
Идея заключается в том, что мы двигаемся от начальной вершины (точки, места) в определенном направлении (по определенному пути) до тех пор, пока не достигнем конца пути или пункта назначения (искомой вершины). Если мы достигли конца пути, но он не является пунктом назначения, то мы возвращаемся назад (к точке разветвления или расхождения путей) и идем по другому маршруту.
Поскольку мы обходим каждого «соседа» каждого узла, игнорируя тех, которых посещали ранее, мы имеем время выполнения, равное O(V + E).


Поиск в ширину
Вместо того, чтобы двигаться по определенному пути до конца, BFS предполагает движение вперед по одному соседу за раз. Это означает следующее: вместо следования по пути, BFS подразумевает посещение ближайших к s соседей за одно действие (шаг), затем посещение соседей и так до тех пор, пока не будет обнаружено t.
Может показаться, что BFS работает медленнее. Однако если внимательно присмотреться к визуализациям, можно увидеть, что они имеют одинаковое время выполнения.
Очередь предполагает обработку каждой вершины перед достижением пункта назначения. Это означает, что, в худшем случае, BFS исследует все вершины и грани.
Несмотря на то, что BFS может казаться медленнее, на самом деле он быстрее, поскольку при работе с большими графами обнаруживается, что DFS тратит много времени на следование по путям, которые в конечном счете оказываются ложными. BFS часто используется для нахождения кратчайшего пути между двумя вершинами.
Таким образом, время выполнения BFS также составляет O(V + E), а поскольку мы используем очередь, вмещающу ю все вершины, его пространственная сложность составляет O(V).
DFS идет напролом, а BFS не торопится, а изучает все в пределах одного шага.
Поиск в глубину и поиск в ширину используются для обхода графа.
DFS двигается по граням туда и обратно, а BFS распространяется по соседям в поисках цели.
DFS использует стек, а BFS — очередь.
Данные алгоритмы имеют разную философию, но одинаково важны для работы с графами.


# Стягивающие деревья

Стягивающие деревья (каркасы).


# Алгоритм построения стягивающего дерева

Алгоритм построения стягивающего дерева.


# Свойства каркасов, получающихся обходом в ширину и глубину

Свойства каркасов, получающихся обходом в ширину и глубину.
Дерево – связный неориентированный граф, в котором нет циклов. У него ровно (n-1) рёбер. 
Связны - из любой вершины можно дойти до любой другой

Есть цикл => не является деревом







	Стягивающее дерево графа — это подграф, который является деревом и включает все вершины исходного графа. Другими словами, это связный, ациклический подграф исходного графа, содержащий все его вершины. 
Цикл – строго определённый путь: замкнутый и без повторов, задействующий все вершины в этом пути выбранного цикла.
Граф с циклами – это граф, в котором может быть один или несколько циклов, но необязательно, чтобы сам весь граф являлся циклом.
Теорема 1: В любом дереве есть хотя бы две висячие вершины, у которых степень равна 1(сколько рёбер).
Висячая вершина – это вершина, у которой только один сосед. 
Теорема 2: Предположим, что теорема верна для всех деревьев из k вершин.
Когда рёбер нет (k = 1 вершин  0 = 1 – 1)
кол-во рёбер = k – 1. Пусть теперь есть дерево с k + 1 вершиной. 
У дерева есть всегда хотя бы одна висячая вершина (по теореме 1).
Удалим одну висячую вершину и связное с ней ребро. Получим дерево на k вершинах (у него k – 1 рёбер). Добавим обратно вершину и 1 ребро(получим k рёбер)
k + 1  k + 1 – 1 = k рёбер.
то есть(3 вершины, 2 ребра. Добавим новую вершину. 4 вершины, 3 ребра. K+1 = 4, (k=3+1) – 1 = 3
В дереве с k + 1 вершинами существует листья — вершина с одним ребром (это следует из определения дерева и связности).
2. Если удалить этот лист и ребро, которое к нему ведёт, останется дерево с k вершинами.
3. По предположению индукции в этом дереве k - 1 ребро.
4. Поскольку мы удалили один лист и одно ребро, то исходное дерево содержало (k - 1) + 1 = k рёбер.


# Фундаментальное множество циклов графа

Фундаментальное множество циклов графа.


# Алгоритм нахождения фундаментального множества циклов

Алгоритм нахождения фундаментального множества циклов.
Объединение множеств А и B  это:
Новое множество, содержащее элементы А и B (в единственном экземпляре)
Пример:
 A={1,2,3,4,7,8},
 B={2,3,4,5,6}.
 Чему равно объединение A и B? Объединение равно {1,2,3,4,5,6,7,8} Объединение A и B обозначается A U B

Пересечение множеств А и B  это:
Новое множество, содержащее элементы, входящие в оба множества А и B 
Пример:
 A={1,2,3,4,7,8},
 B={2,3,4,5,6}.
 Чему равно пересечение A и B?
Пересечение равно {2,3,4}
Пересечение A и B обозначается A ∩ B
Разность множеств А и B  это:
Новое множество, содержащее элементы, входящие в множество А , но не входящие в множество B 
Пример:
 A={1,2,3,4,7,8},
 B={2,3,4,5,6}.
 Чему равна разность A и B? 
Разность равна {1,7,8}
Разность A и B обозначается A \ B
Мощностью конечного множества называется количество его элементов. Мощность A обозначается |A|. Если A={2,7,9,11}, то |A|=4
Смысл симметрической разности множеств A и B – это объединение элементов, входящих в A, но не входящих в B и входящих в B, но не входящих в А. 
Пусть A={1,2,3,4}, B={2,3,4,5}, тогда AΘB={1,5}
Фундаментальное множество циклов – это набор базовых циклов в неориентированном графе, из которых можно получить все остальные циклы графа с помощью операции симметрической разности (т.е. «складывая» циклы по рёбрам). 
Особый, минимальный набор циклов, из которых можно построить любой другой цикл графа путём «сложения». 
Каждое такое добавление образует один уникальный цикл, и все они вместе составляют фундаментальное множество. Из этих циклов можно построить любой другой цикл графа с помощью побитовой симметрической разности рёберных множеств (аналогично сложению векторов по модулю 2).


• Мы берём каркас графа — то есть остовное дерево T, которое соединяет все вершины, не содержит циклов, и имеет n - 1 рёбер (где n — число вершин).
 • Затем каждое ребро, не входящее в остовное дерево (назовём его «избыточное»), мы добавляем к дереву.
 • Поскольку остов — дерево, то между любыми двумя вершинами u и v уже есть единственный путь по дереву.
Если мы добавим ребро (u, v), то оно замкнёт цикл вместе с этим путём.


Фундаментально множество циклов – это набор циклов, каждый из которых получается при добавлении одного ребра, не входящее в остовное дерево, в само дерево. Такое добавление замыкает путь и образуется один уникальный цикл. (каждый фундаментальный цикл содержит ровно одно ребро, которое при добавлении к каркасу порождает цикл).
Суть ФМЦ: В каждом цикле содержится ребро, при подстановке которого в каркас, мы получим в каркасе цикл. Мы подставляем ребро из любого цикла в каркас всего исходного графа, благодаря этому одному добавленному ребру у нас получается цикл в каркасе
Поиск в глубину является естественным подходом, используемым для нахождения фундаментальных циклов. 
Вход – связный неориентированный граф.
Выход – ФМЦ (список циклов – каждый как набор рёбер или вершин)

Название “фундаментальный” связано с тем, что каждый цикл графа может быть получен из циклов этого множества. Для произвольных множеств A и B определим операцию симметрической разности AÅB=(AÈB)\(AÇB). Известно, что произвольный цикл графа G можно однозначно представить как симметрическую разность некоторого числа фундаментальных циклов. Однако не при всех операциях симметрической разности получаются циклы (вырожденный случай).


# Каркасы минимального веса

Каркасы минимального веса.


# Алгоритмы Прима и Краскала

Алгоритмы Прима и Краскала.
Каркас дерева – связный ацикличный граф, он же является деревом.
Остовным деревом графа называется дерево, которое можно получить из графа путём удаления некоторых рёбер. У графа может существовать несколько остовных деревьев, и чаще всех их достаточно много.
Стягивающее дерево = каркас графа = остовное дерево графа 
Каркас минимального дерева(взвешенные графы) – это остовное дерево, у которого сумма весов рёбер минимальна среди всех возможных остовных деревьев. Оно соединяет все вершины и имеет минимальную общую стоимость связности. Необязательно, чтобы все рёбра были использованы, т.к. образуется цикл
Суть обоих алгоритмов состоит в: соединении всех вершин таким образом, чтобы сумма рёбер была минимальна и не образовывался цикл

Алгоритм Прима. Суть самого алгоритма Прима сводится к жадному перебору рёбер, но уже из определенного множества. На входе так же имеется пустой подграф, который и будем достраивать до потенциального минимального остовного дерева.
1) Выбираем произвольную вершину. 
Изначально наш подграф состоит из одной любой вершины исходного графа.
2) Присоединяем к текущему каркасу вершину с ребром минимального веса (но так, чтобы не создать цикла).
Затем из рёбер инцидентных этой вершине, выбирается такое минимальное ребро, которое связала бы две абсолютно разные компоненты связности, одной из которых и является наш подграф. То есть, как только у нас появляется возможность добавить новую вершину в наш подграф, мы тут же включаем её по минимально возможному весу.
3) Повторяем шаг 2 до исчерпания вершин графа.
Продолжаем выполнять предыдущий шаг до тех пор, пока не найдем искомое MST.
Алгоритм Краскала. Присоединяем к каркасу ребро минимального веса из числа свободных (минимальный вес из всех рёбер инцидентных множеству вершин нашего подграфа), но так, чтобы не образовывалось циклов. 
Сначала считаем, что все вершины раздельны, постепенно соединяем их, добавляя самые лёгкие рёбра, пока всё не станет деревом.


# Компоненты двусвязности графа

Компоненты двусвязности графа и алгоритм их нахождения.
Точка сочленения – это вершина графа, удаление которой увеличивает число компонент связности графа. Если убрать эту вершину и все рёбра, связанные с ней, то граф распадётся на две или более частей. 
Вершина V в связном неориентированном графе G – точка сочленения, если граф G без вершины V становится несвязным


Вершина A есть точка сочленения, если в графе существуют вершины V и U (отличные от A), такие, что любой путь из V в U проходит через A.
Неориентированный граф называется двусвязным, если он связный – между вершинами компоненты есть путь - и не содержит точек сочленения. (его нельзя разбить на куски – компоненты). Если весь граф – двусвязный (нет ни одной точки сочленения), значит весь граф и есть одна большая компонента двусвязности.
Компонента связности – максимально множество вершин, в котором любые две вершины соединены путём, и никакая другая вершина вне этого множества не связана с ними.
Произвольный максимальный двусвязный подграф исходного графа называется компонентой двусвязности (или блоком). Это «прочные участки» внутри компонент, которые не распадаются, если вытащить одну вершину.
Это подграф, состоящий из двух или более вершин и рёбер, который нельзя разъединить удалением одной вершины. 
Алгоритм Тарьяна
Подграф – это просто часть графа, которая включает некоторые вершины и рёбра, взятые из исходного графа.


# Алгоритм их нахождения

алгоритм их нахождения.
Точка сочленения – это вершина графа, удаление которой увеличивает число компонент связности графа. Если убрать эту вершину и все рёбра, связанные с ней, то граф распадётся на две или более частей. 
Вершина V в связном неориентированном графе G – точка сочленения, если граф G без вершины V становится несвязным


Вершина A есть точка сочленения, если в графе существуют вершины V и U (отличные от A), такие, что любой путь из V в U проходит через A.
Неориентированный граф называется двусвязным, если он связный – между вершинами компоненты есть путь - и не содержит точек сочленения. (его нельзя разбить на куски – компоненты). Если весь граф – двусвязный (нет ни одной точки сочленения), значит весь граф и есть одна большая компонента двусвязности.
Компонента связности – максимально множество вершин, в котором любые две вершины соединены путём, и никакая другая вершина вне этого множества не связана с ними.
Произвольный максимальный двусвязный подграф исходного графа называется компонентой двусвязности (или блоком). Это «прочные участки» внутри компонент, которые не распадаются, если вытащить одну вершину.
Это подграф, состоящий из двух или более вершин и рёбер, который нельзя разъединить удалением одной вершины. 
Алгоритм Тарьяна
Подграф – это просто часть графа, которая включает некоторые вершины и рёбра, взятые из исходного графа.


# Эйлеровы циклы

Эйлеровы циклы.


# Алгоритм нахождения эйлерового цикла

Алгоритм нахождения эйлерового цикла.
Эйлеров цикл – это цикл в графе, который проходит по каждому ребру ровно один раз и возвращается в исходную вершину. 
Теорема Эйлера. Связный неориентированный граф содержит эйлеров цикл тогда и только тогда, когда число вершин с нечетной степенью равно нулю.  
(нечётной/чётной степени вершин – нечётное/чётное кол-во рёбер инцидентны вершине).
Чтобы в графе существовал Эйлеров цикл, все вершины должны иметь чётную степень (т.е. кол-во рёбер инцидентных вершине, - чётное число).
Связный граф – это такой граф, в котором существует путь между любой парой вершин (из любой вершины можно дойти до любой другой, перейдя по рёбрам графа).
ДОКАЗАТЕЛЬСТВА ЭЙЛЕРОВА ЦИКЛА


# Гамильтоновы циклы

Гамильтоновы циклы.


# Алгоритм нахождения гамильтонова цикла

Алгоритм нахождения гамильтонова цикла (алгоритм с возвратом).
Гамильтонов цикл – это цикл в графе, который проходит через каждую вершину ровно один раз и возвращается в начальную вершину.
Замкнутый цикл, который включает все вершины графа по одному разу(кроме начальной)
Отличия от Эйлерова цикла


# Кратчайшие пути в ориентированных графах

Кратчайшие пути в ориентированных графах.


# Построение кратчайшего пути при известных кратчайших расстояниях между вершинами

Построение кратчайшего пути при известных кратчайших расстояниях между вершинами.


# Определение кратчайших расстояний между вершинами

Определение кратчайших расстояний между вершинами.


# Алгоритм Форда-Беллмана

Алгоритм Форда-Беллмана.


# Случай неотрицательных весов – алгоритм Дейкстры

Случай неотрицательных весов – алгоритм Дейкстры. 
Кратчайший путь в ориентированном графе – это путь из вершины S в вершину V, имеющий наименьшую возможную сумму весов рёбер среди возможных маршрутов из S в V.




Алгоритмы для нахождения кратчайших расстояний между вершинами
Алгоритм Дейкстры:
Находит кратчайшие пути от одной вершины ко всем остальным в графе без ребер отрицательного веса. Находит расстояние от одной вершины (дадим ей номер 0) до всех остальных за количество операций порядка n^2. Все веса неотрицательны.


# Сортировка вершин бесконтурного графа

Сортировка вершин бесконтурного графа.


# Кратчайшие пути в бесконтурном графе

Кратчайшие пути в бесконтурном графе.
Бесконтурным называется ориентированный граф (орграф), не содержащий циклов


Бесконтурные графы обладают замечательным свойством: их вершины можно перенумеровать так, что для любой дуги (p,q) всегда будет q > p. В ориентированном ацикличном графе существует топологическая сортировка, при которой все дуги от меньшей вершины (по номеру) идут к большей. 
Верное и обратно. Если во всех дугах ориентированного графа начало дуги меньше конца (по номеру), то граф точно не содержит циклов (это DAG). В цикле мы бы вернулись в меньшую вершину, а это невозможно, если дуги всегда идут от меньших к большим.
Топологическая сортировка (


# Расстояние между всеми парами вершин – алгоритм Флойда

Расстояние между всеми парами вершин – алгоритм Флойда.
Алгоритм Флойда (Флойда-Уоршелла) используется для поиска кратчайших путей между всеми парами вершин во взвешенном ориентированном графе, то есть для каждой вершины к каждой другой вершине.
Он эффективно обновляет расстояния между вершинами, учитывая возможные пути через промежуточные узлы. 
Алгоритм работает за время O(n^3). Если в графе есть циклы отрицательного веса, то формально алгоритм Флойда-Уоршелла к такому графу неприменим.


# Потоки в сетях

Потоки в сетях.


# Максимальный поток в сети и минимальный разрез

Максимальный поток в сети и минимальный разрез.


# Теорема Форда-Фалкерсона

Теорема Форда-Фалкерсона.


# Алгоритм построения максимального потока

Алгоритм построения максимального потока.
Граф в этой теме = сеть
1) Исток – это особая вершина в ориентированном графе, в которую не входит ни одно ребро
Сток – это особая вершина в ориентированном графе, из которой не выходит ни одного ребра. 
2) Пропускная способность – это максимум, сколько может пройти по направленному пути между вершинами
При этом разрез с минимальной пропускной способностью называется минимальным разрезом. Набор рёбер, разделяющие исток и сток, сумма пропускных способностей которых минимальна. При этом рёбра, входящие в минимальный разрез, считаются отдельно. Они необязательно должны быть последовательными.
Максимальный поток – наибольшее кол-во, которое можно одновременно пропустить по сети из источника до приёмника, не превышая ограничений на каждом ребре.
