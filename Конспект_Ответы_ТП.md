# Основные этапы решения задач на ЭВМ

Основные этапы решения задач на ЭВМ.


# Критерии качества программы

Критерии качества программы.


# Программное средство

Программное средство.


# Жизненный цикл программы

Жизненный цикл программы.


# Абстрактные структуры данных

Абстрактные структуры данных.


# Статические и динамические структуры

Статические и динамические структуры.


# Массивы, стеки, очереди, списки, графы, деревья

Массивы, стеки, очереди, списки, графы, деревья.


# Деревья поиска

Деревья поиска.


# Хэш-таблицы

Хэш-таблицы.


# Функция расстановки

Функция расстановки.


# Суффиксный массив

Суффиксный массив.


# Алгоритм Бауэра вычисления алгебраического выражения

Алгоритм Бауэра вычисления алгебраического выражения.


# Обратная польская запись

Обратная польская запись (ОПЗ).


# Алгоритм перевода формулы в ОПЗ

Алгоритм перевода формулы в ОПЗ.


# Генерация кода для стековой машины

Генерация кода для стековой машины.


# Оценка вычислительной сложности алгоритмов

Оценка вычислительной сложности алгоритмов.


# Символ “О большое”

Символ “О большое”.

Сложность алгоритма:  
Описывает рост времени выполнения или использования памяти в зависимости от размера входа.  

O-большое (асимптотическая верхняя граница):  
- O(1): Константная сложность (доступ к элементу массива).  
- O(n): Линейная (поиск наибольшего в неотсортированном массиве -> надо пройтись по всем элементам массива).  
- O(n²): Квадратичная (сортировка вставками -> он представляет из себя два вложенных цикла: один, чтобы проходить по всему массиву, а второй, чтобы находить место очередному элементу в уже отсортированной части. Таким образом, количество операций будет зависеть от размера массива как n * n, т. е. n^2.).  
- O(log n): Логарифмическая (бинарный поиск -> Если массив отсортирован, мы можем проверить, есть ли в нём какое-то конкретное значение, методом деления пополам. Проверим средний элемент, если он больше искомого, то отбросим вторую половину массива — там его точно нет. Если же меньше, то наоборот — отбросим начальную половину. И так будем продолжать делить пополам, в итоге проверим log n элементов.).  
---


# Двоичный поиск

Двоичный поиск. Сортировка данных.


# Устойчивость и естественность сортировки

Устойчивость и естественность сортировки.

Алгоритм поиска элемента в отсортированном массиве за O(log n).  

Как работает?  
1. Находим середину массива.  
2. Сравниваем искомый элемент с элементом в середине:  
   - Если искомый меньше → ищем в левой половине.  
   - Если больше → ищем в правой половине.  
   - Если равен → элемент найден.  
3. Повторяем, пока не найдём элемент или не убедимся, что его нет.  
Пример:  
Массив: `[1, 3, 5, 7, 9]`, ищем `5`.  
1. Середина: `5` → совпало!  

Устойчивость сортировки:  
Сохраняет относительный порядок элементов с одинаковыми ключами. Примеры: сортировка вставками, слиянием. 
Дан массив пар: `[(3, "A"), (1, "B"), (3, "C")]`.  
- Устойчивая сортировка по числам: `[(1, "B"), (3, "A"), (3, "C")]` (порядок "A" и "C" сохранён).  
 

Естественность:  
Алгоритм учитывает уже имеющуюся упорядоченность данных.  
Пример:  
- Если массив почти отсортирован, некоторые алгоритмы работают быстрее:  
  - Сортировка вставками — O(n) для почти упорядоченных данных.  

---


# Простейшие алгоритмы сортировки

Простейшие алгоритмы сортировки (пузырьковая, вставками, выбором).

1. Пузырьковая сортировка:  
    1. Пузырьковая сортировка (Bubble Sort)  
Идея: "Всплываем" самый большой элемент в конец массива за каждый проход.  

Как работает:  
1. Сравниваем соседние элементы.  
2. Если левый > правого → меняем их местами.  
3. Повторяем, пока массив не отсортируется.  
Сложность: `O(n²)`.  

2. Сортировка вставками:  
   Как сортировка карт в руке – берём элемент и вставляем в правильное место в уже отсортированной части.  
Как работает:  
1. Делим массив на отсортированную (слева) и неотсортированную (справа) части.  
2. Берём первый элемент из неотсортированной части и вставляем его в нужное место в отсортированной.  
3. Повторяем, пока весь массив не отсортируется.  
Сложность: `O(n²)` (лучший случай `O(n)`).  

3. Сортировка выбором:  
   Идея: Находим минимальный элемент и ставим его в начало. Повторяем для оставшейся части.  

Как работает:  
1. Находим минимальный элемент в неотсортированной части.  
2. Меняем его с первым элементом неотсортированной части.  
3. Повторяем, пока весь массив не отсортируется.  
Сложность: `O(n²)`.  

---


# Эффективные алгоритмы сортировки

Эффективные алгоритмы сортировки (быстрая, шелловская, пирамидальная, поразрядная).


# Сортировка подсчетом

Сортировка подсчетом.

1. Быстрая сортировка (QuickSort):  
   Идея: "Всплываем" самый большой элемент в конец массива за каждый проход.  

Как работает:  
1. Быстрая сортировка (Quick Sort)  
Идея: Разделяй и властвуй.  
1. Выбираем опорный элемент (pivot).  
2. Делим массив на две части:  
   - Элементы меньше pivot.  
   - Элементы больше pivot.  
3. Рекурсивно сортируем обе части
   - Средняя сложность: `O(n log n)`.  

2. Сортировка Шелла:  
Как работает:  
1. Выбираем шаг (например, `n/2`, затем `n/4` и т. д.).  
2. Сортируем подмассивы с этим шагом.  
3. В конце шаг = 1 (обычная сортировка вставками).  

3. Пирамидальная (HeapSort):  
Идея: Использует бинарную кучу (heap).  
1. Превращаем массив в кучу (max-heap).  
2. Максимальный элемент (корень) меняем с последним.  
3. Уменьшаем кучу и повторяем.  [1,3,4,5,10]

4. Поразрядная сортировка (RadixSort):  
Как работает:  
1. Сортируем числа по младшему разряду (через устойчивую сортировку).  
2. Переходим к старшим разрядам.  
 (от младшего к старшему).  
   - Сложность: `O(nk)`, где `k` — число разрядов.  

5.


# Источники ошибок в программных средствах

Источники ошибок в программных средствах.


# Тестирование программных средств

Тестирование программных средств.


# Тестирование по принципам "белого" и "черного ящика"

Тестирование по принципам "белого" и "черного ящика".

Источники ошибок:  
1. Логические ошибки  
   - Неправильный алгоритм (например, ошибка в формуле расчета).  
   - Условия `if-else` работают не так, как задумано.  
2. Синтаксические ошибки  
   - Опечатки, неправильные ключевые слова (например, `whille` вместо `while`).  
   - Отсутствие скобок, точек с запятой (зависит от языка).  
3. Ошибки данных  
   - Переполнение переменной (например, `int` не вмещает большое число).  
   - Неправильный тип данных (передали строку вместо числа).  
4. Ошибки взаимодействия  
   - Программа зависает при вводе неверных данных.  
   - Неправильная работа с файлами/сетью (например, файл не найден).  
5. Ошибки времени выполнения  
   - Деление на ноль.  
   - Обращение к несуществующему элементу массива.  
6. Ошибки проектирования  
   - Плохая архитектура программы (например, бесконечные циклы).  
   - Неучтенные граничные случаи (например, пустой ввод).

Тестирование:

1. Модульное (Unit Testing)  
   - Проверка отдельных функций/методов.  
   - Пример: тест для функции сложения чисел.  

2. Интеграционное (Integration Testing)  
   - Проверка взаимодействия между модулями.  
   - Пример: тест API, которое использует базу данных.  

3. Системное (System Testing)  
   - Проверка всей программы целиком.  
   - Пример: тест интерфейса веб-сайта.  

4. Регрессионное (Regression Testing)  
   - Повторное тестирование после изменений.  
   - Пример: проверка, что новый код не сломал старый.  

Тестирование:  
- Черный ящик: Тестирование функциональности без знания кода (на основе спецификаций).  QA тестировщик
- Белый ящик: Тестирование структуры кода (покрытие ветвей, условий). Разработчик 

---


# Особенности операций с плавающей точкой

Особенности операций с плавающей точкой.


# Представление чисел с плавающей точкой в компьютере

Представление чисел с плавающей точкой в компьютере.


# Причины погрешности операций с плавающей точкой

Причины погрешности операций с плавающей точкой.

Представление (IEEE 754):  
Знак (sign) — один бит, обозначающий положительное или отрицательное число.
Мантисса (mantissa) — дробная часть числа, представляющая значащие цифры.
Порядок (exponent) — целое число, задающее степень основания (обычно 2), на которую умножается мантисса.

Важно, что у мантиссы первый разряд не должен быть нулем.
Форма представления числа с плавающей точкой, в которой первый разряд мантиссы не равен нулю, называется нормализованной.
Наиболее распространённые форматы:
float (одинарная точность) — 32 бита: 1 бит знак, 8 бит порядок, 23 бита мантисса.
double (двойная точность) — 64 бита: 1 бит знак, 11 бит порядок, 52 бита мантисса.
Особенности:
1. Неточное представление десятичных дробей
2. Ограниченная точность (около 7 для float и 15 для double)
3. Неассоциативность операций
Из-за округлений результат может зависеть от порядка операций
4. Накопление ошибок
При множественных операциях маленькие погрешности могут накапливаться, приводя к значительным ошибкам
5. Особенности разных языков


Причины погрешности:  
- Ограниченная разрядность мантиссы.  
- Потеря точности при вычитании близких чисел.


# Алгоритм RLE сжатия данных

Алгоритм RLE сжатия данных.

RLE (Run-Length Encoding) - это простой алгоритм сжатия данных, основанный на замене повторяющихся последовательностей символов одним символом и указанием количества его повторений.  
Замена повторяющихся символов на пару `(символ, количество)`.  
Пример: `AAAABBB` → `A4B3`.  
Эффективен для данных с большими сериями повторений (изображения, текст).  

---


# Алгоритм Хаффмана

Алгоритм Хаффмана.


# Построение дерева Хаффмана и битового кода

Построение дерева Хаффмана и битового кода.


# Алгоритм LZW сжатия данных

Алгоритм LZW сжатия данных.

LZW (Lempel-Ziv-Welch):  
Алгоритм LZW — это словарный метод сжатия, который динамически строит таблицу (словарь) повторяющихся последовательностей данных и заменяет их кодами. Он используется в форматах GIF, TIFF, ZIP и Unix-утилите `compress`.
- Автоматически выявляет повторяющиеся паттерны (слова, фразы в тексте, последовательности пикселей в изображениях).
- Чем длиннее повторяющиеся последовательности, тем сильнее сжатие.

Шаг 1: Начальный словарь  
Компьютер знает все базовые символы (например, для текста — буквы):  
- `A = 0`, `B = 1`, `C = 2`, ...  

 Шаг 2: Сжатие  
Алгоритм читает данные и запоминает новые комбинации, давая им номера.  

Пример для строки "ABABABAC":  
1. Видит `A` (есть в словаре).  
2. Видит `AB` — нет в словаре → добавляет `AB = 256`, выводит код для `A` (0).  
3. Видит `BA` — нет → добавляет `BA = 257`, выводит код для `B` (1).  
4. Видит `AB` (уже есть под кодом 256) → выводит 256.  
5. И так далее...  

Итог: Коды `[0, 1, 256, 258, 2]` вместо исходных 8 букв.  

 Шаг 3: Распаковка  
Декодер восстанавливает словарь на лету, используя полученные коды:  
- Видит код `0` → это `A`.  
- Видит код `1` → это `B`, добавляет `AB = 256`.  
- Видит код `256` → это `AB`, добавляет `BA = 257`.  

---


# Арифметическое сжатие данных

Арифметическое сжатие данных.

Арифметическое кодирование:  
- Представляет данные как дробь в интервале `[0, 1)`.  
- Каждый символ сужает интервал в соответствии с его вероятностью.  
- Результат — число, представляющее весь вход.  
Пример:
Давайте представим арифметическое сжатие как игру в "угадай число", где компьютер вместо чисел использует вероятности. Вот как это работает на пальцах:

1. Подготовка (размечаем линейку)
Допустим, у нас есть алфавит из трёх букв:
- А (встречается в 50% случаев) → отрезок [0.0 - 0.5)
- Б (30%) → [0.5 - 0.8)
- В (20%) → [0.8 - 1.0)

2. Сжатие слова "БАВ"
• Первая буква Б → берём её отрезок [0.5-0.8)
• Внутри него снова размечаем пропорции:
  А → [0.5 - 0.65)
  Б → [0.65 - 0.74)
  В → [0.74 - 0.8)
• Вторая буква А → берём [0.5 - 0.65)
• Снова делим этот отрезок:
  А → [0.5 - 0.575)
  Б → [0.575 - 0.62)
  В → [0.62 - 0.65)
• Третья буква В → [0.62 - 0.65)

3. Результат
Выбираем любое число из финального диапазона, например 0.63. Это и есть наше сжатое сообщение!

4. Как распаковать?
Компьютер делает обратный процесс:
• Видит 0.63 → попадает в [0.5-0.8) → первая буква Б
• Берёт отрезок для Б и "растягивает" 0.63 обратно в [0-1):
  (0.63-0.5)/(0.8-0.5) ≈ 0.433
• 0.433 попадает в [0.0-0.5) → вторая буква А
• Повторяет процесс дальше

Главные фишки:
- Частые буквы "съедают" больше места на линейке
- Каждый новый символ уточняет диапазон
- Финальное число можно записать меньшим количеством бит

---


# Коды, исправляющие ошибки

Коды, исправляющие ошибки.


# Расстояние Хэмминга

Расстояние Хэмминга.


# Фундаментальные соотношения для расстояния Хэмминга

Фундаментальные соотношения для расстояния Хэмминга, обеспечивающие фиксацию и исправление ошибок.


# Рекурсия

Рекурсия.


# Требования к рекурсивным программам

Требования к рекурсивным программам.


# Терминальная ветвь рекурсии

Терминальная ветвь рекурсии.


# Примеры рекурсивных программ

Примеры рекурсивных программ.


# Виды рекурсии

Виды рекурсии.


# Графы

графы, деревья.


# Машинное представление графов

Машинное представление графов (матрица смежности, матрица инцидентности, списки вершин).
Граф — это абстрактная структура данных, представляющая набор объектов (вершины) и связей между ними (рёбра).
Представление графа в компьютере
Существует несколько способов представления графов в компьютерной программе. Наиболее распространённые методы включают:

Матрица смежности
Матрица инцидентности
Списки смежности (списки рёбер)

Матрица смежности:  
Создается матрица размерностью V*V (условно у нас 6 вершин, следовательно таблица будет 6x6 (номер строки – вершина от куда идем, а номер стобца – вершина куда идем). Исследуя граф в таблицу записывается 1, в случае если такое ребро существует и 0 если такого ребра нет

Матрица инцидентности:  
На графе подписываются все ребра (a1, a2, a3… an) после этого создается матрица, где вертикально пишутся вершины, а горизонтально ребра. Далее смотрим ребро и проверяем, какие вершины оно связывает. В матрице на месте пересечения вершины и ребра ставим 1 иначе 0. Если граф имеет направление, то смотрим направление и в случае если оно выходит, то пишем -1, а в случае если входит, то 1

Список ребер
Анализируется граф и записываются все ребра.

---


# Общая схема обхода вершин графа

Общая схема обхода вершин графа.


# Поиск в глубину в графе

Поиск в глубину в графе.


# Поиск в ширину в графе

Поиск в ширину в графе.

Есть 2 варианта обхода графов:
Обход в глубину (DFS):
Программа идет до самого конца по ребрам, пока не уткнется. После этого возвращается на исходную и проверяет другой путь. Программа работает пока не проверит все ребра
По структуре это стек (структура, работающая по принципу последний пришел, первый ушел). Данный вариант обхода экономит память и находит любой путь.
Обход в ширину (BFS):
Программа исследует граф по уровням. То есть, сначала проверяет все соседние вершины, потом проверяет вершины, которые находятся через 2 ребра и.т.д до самого конца графа. 
По структуре это очередь, она может потреблять больше памяти, однако находит кратчайший путь


# Стягивающие деревья

Стягивающие деревья (каркасы).


# Алгоритм построения стягивающего дерева

Алгоритм построения стягивающего дерева.


# Свойства каркасов, получающихся обходом в ширину и глубину

Свойства каркасов, получающихся обходом в ширину и глубину.

Стягивающее дерево это подграф, который:
- содержит все вершины исходного графа
- является деревом (без циклов)
- имеет ровно V-1 ребер (где V – число вершин)

1. Метод «Иди вглубь» (DFS-дерево)  
- Как работает:  
  - Выбираешь стартовую точку.  
  - Идёшь по первой доступной нитке, пока не зайдёшь в тупик.  
  - Возвращаешься и проверяешь другие пути.  

2. Метод «Иди вширь» (BFS-дерево)  
- Как работает:  
  - Начинаешь с выбранной точки.  
  - Сначала осматриваешь всех её соседей.  
  - Потом — соседей соседей, и так далее.  

- Что получится:  
  - Дерево с «этажами» (как организационная структура компании).  
  - Все пути от корня — кратчайшие.


# Фундаментальное множество циклов графа

Фундаментальное множество циклов графа.


# Алгоритм нахождения фундаментального множества циклов

Алгоритм нахождения фундаментального множества циклов.

Фундаментальное множество циклов (FMC) — это набор простых циклов, из которых можно получить все остальные циклы в графе. Оно строится на основе остовного дерева (дерева, которое включает все вершины графа без циклов).  

Алгоритм:  
Шаг 1. Постройте остовное дерево  
- Возьмите граф и удалите некоторые рёбра, чтобы получилось дерево (без циклов, но всё ещё связное).  
- Оставшиеся рёбра (не вошедшие в дерево) называются "хордами".  
 (DFS или BFS). 
 
Шаг 2. Добавляйте хорды по одной  
Каждая хорда создаёт ровно один новый цикл при добавлении к дереву:  
1. Возьмите хорду (например, ребро между вершинами A и B).  
2. Найдите путь между A и B в дереве.  
3. Этот путь + хорда = новый цикл.  

---


# Каркасы минимального веса

Каркасы минимального веса.


# Алгоритмы Прима и Краскала

Алгоритмы Прима и Краскала.

Алгоритм Прима 
Основная идея: строить дерево поэтапно, добавляя самое дешёвое возможное ребро, связанное с существующим фрагментом дерева.
Алгоритм пошагово:
Начало с одной произвольной вершины.
Ищем ближайшее ребро, ведущее к ещё не присоединённой вершине.
Добавляем это ребро и соответствующую вершину в растущее дерево.
Повторяем шаги 2–3, пока все вершины не окажутся частью дерева.
- Сложность: `O(m log n)` с кучей.  

Алгоритм Краскала 
Основана идея: брать рёбра в порядке возрастания их стоимости, добавляя их в дерево, если они не формируют цикла.
Алгоритм пошагово:
Сортируем все рёбра по возрастанию стоимости.
Просматриваем отсортированный список рёбер.
Добавляем ребро, если оно не образует цикл с текущим набором рёбер.
Продолжаем, пока не объединим все вершины.

---


# Компоненты двусвязности графа

Компоненты двусвязности графа и алгоритм их нахождения.
Максимальный подграф, который остается связным при удалении любого одного ребра (отсутствие мостов — ребер, чье удаление разрывает связность).  
Алгоритм нахождения (на основе DFS):  
1. Запускаем DFS из произвольной вершины, сохраняя:
   - `depth[v]` — глубина вершины (номер шага DFS).
   - `low[v]` — минимальная глубина, достижимая из `v` через обратные рёбра.
2. Определяем точки сочленения:  
   Вершина `v` — точка сочленения, если:
   - У неё есть потомок `u`, для которого `low[u] >= depth[v]` (т.е. нет обхода через предков).
3. Разделяем на компоненты:  
   - Все рёбра, пройденные до обнаружения точки сочленения, образуют компоненту двусвязности
Пример:  
Компонента 1 (синяя):       Компонента 2 (красная):
      1                       5---6
       \                        \ /
        2                        8
       / \
      5---6
       \ /
        8---7
           /
          4
В красном графе, при удаление любой вершины граф разрушится, а в синей граф так и останется. Следовательно синий граф двусвязный


# Алгоритм их нахождения

алгоритм их нахождения.
Максимальный подграф, который остается связным при удалении любого одного ребра (отсутствие мостов — ребер, чье удаление разрывает связность).  
Алгоритм нахождения (на основе DFS):  
1. Запускаем DFS из произвольной вершины, сохраняя:
   - `depth[v]` — глубина вершины (номер шага DFS).
   - `low[v]` — минимальная глубина, достижимая из `v` через обратные рёбра.
2. Определяем точки сочленения:  
   Вершина `v` — точка сочленения, если:
   - У неё есть потомок `u`, для которого `low[u] >= depth[v]` (т.е. нет обхода через предков).
3. Разделяем на компоненты:  
   - Все рёбра, пройденные до обнаружения точки сочленения, образуют компоненту двусвязности
Пример:  
Компонента 1 (синяя):       Компонента 2 (красная):
      1                       5---6
       \                        \ /
        2                        8
       / \
      5---6
       \ /
        8---7
           /
          4
В красном графе, при удаление любой вершины граф разрушится, а в синей граф так и останется. Следовательно синий граф двусвязный


# Эйлеровы циклы

Эйлеровы циклы.


# Алгоритм нахождения эйлерового цикла

Алгоритм нахождения эйлерового цикла.

Эйлеров цикл: Цикл, проходящий через все ребра графа ровно один раз.  
Условия существования:  
- Проходит по каждому ребру ровно один раз.
- Начинается и заканчивается в одной и той же вершине.
Алгоритм нахождения цикла (алгоритм Флери):
1. Проверь условия (чётность степеней).  
2. Начни с любой вершины (для цикла).  
3. Переходи по рёбрам, соблюдая правила:  
   - Не выбирай мост (ребро, без которого граф распадётся), если есть другие варианты.  
4. Удаляй пройденные рёбра.  
5. Повторяй, пока не пройдёшь все рёбра.  

---


# Гамильтоновы циклы

Гамильтоновы циклы.


# Алгоритм нахождения гамильтонова цикла

Алгоритм нахождения гамильтонова цикла (алгоритм с возвратом).

Гамильтонов цикл — это путь в графе, который:
- Проходит через каждую вершину ровно один раз.
- Возвращается в исходную вершину, образуя цикл.
-Не имеет условия четности степени вершин

Шаги алгоритма:
1. Выбери стартовую вершину (например, вершину 1).
2. Рекурсивно перебирай все непосещённые соседние вершины.
3. Если все вершины посещены и есть ребро обратно в стартовую вершину → найден цикл.
4. Если путь тупиковый → откат (backtrack) и попробуй другой вариант.

 Визуальный пример
Граф:
```
      1
    / | \
   2--3--4
```
Поиск цикла:
1. Старт: 1 → 2 → 3 → 4 → 1 (гамильтонов цикл!).  
2. Другой вариант: 1 → 3 → 2 → 4 → 1 (тоже подходит).  

---


# Кратчайшие пути в ориентированных графах

Кратчайшие пути в ориентированных графах.


# Построение кратчайшего пути при известных кратчайших расстояниях между вершинами

Построение кратчайшего пути при известных кратчайших расстояниях между вершинами.


# Определение кратчайших расстояний между вершинами

Определение кратчайших расстояний между вершинами.


# Алгоритм Форда-Беллмана

Алгоритм Форда-Беллмана.


# Случай неотрицательных весов – алгоритм Дейкстры

Случай неотрицательных весов – алгоритм Дейкстры.

Кратчайший путь: Путь с минимальной суммой весов ребер.


# Сортировка вершин бесконтурного графа

Сортировка вершин бесконтурного графа.


# Кратчайшие пути в бесконтурном графе

Кратчайшие пути в бесконтурном графе.

Топологическая сортировка:  
Упорядочивание вершин ориентированного ациклического графа (DAG), при котором для любого ребра `u → v`, вершина `u` идет перед `v`.  

Алгоритм:  
1. Запустить DFS, помечая вершины как посещённые.  
2. После обработки всех соседей вершины `u` (т.е. на "выходе" из DFS), добавить `u` в начало списка.  

Результат: Обратный порядок завершения DFS.  


Кратчайшие пути в DAG:  
1. Выполнить топологическую сортировку.  
2. Обходить вершины в порядке сортировки, релаксируя исходящие ребра.  
3. Сложность: `O(n + m)`.  

Пример:  
Для вершин `A → B → C` топологический порядок: `A, B, C`. Кратчайший путь от `A` до `C` вычисляется за линейное время.

---


# Потоки в сетях

Потоки в сетях.


# Максимальный поток в сети и минимальный разрез

Максимальный поток в сети и минимальный разрез.


# Теорема Форда-Фалкерсона

Теорема Форда-Фалкерсона.


# Алгоритм построения максимального потока

Алгоритм построения максимального потока.

Поток в сети:  
- Источник (s – начальная точка) и сток (t – конечная точка).  
- У каждого ребра указана пропускная способность (максимальный поток через это ребро).  
- Поток — сколько реально «течёт» по ребру (не больше пропускной способности).  
- Максимальный поток — наибольший возможный поток из `S` в `T` при заданных ограничениях
Минимальный разрез: разрез с наименьшей пропускной способностью.
